{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 09:33:42.134676: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 09:33:42.194199: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 09:33:42.447818: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 09:33:43.618222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de imagen para el modelo pre-entrenado\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y preprocesar imágenes\n",
    "def load_and_preprocess_images(data_dir):\n",
    "    images = []  # Lista para almacenar imágenes\n",
    "    labels = []  # Lista para almacenar etiquetas\n",
    "    filenames = []  # Lista para almacenar los nombres de archivos\n",
    "    label_map = {label: idx for idx, label in enumerate(os.listdir(data_dir))}  # Mapa de etiquetas a índices\n",
    "    \n",
    "    for label in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        print (class_dir)\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = cv2.imread(img_path)  # Cargar la imagen\n",
    "            if img is not None:  # Verificar si la imagen se ha cargado correctamente\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Redimensionar la imagen\n",
    "                img = img / 255.0  # Normalizar la imagen\n",
    "                images.append(img)\n",
    "                labels.append(label_map[label])\n",
    "                filenames.append((img_file, img_path))\n",
    "            else:\n",
    "                print(f\"Advertencia: No se pudo cargar la imagen {img_path}\")\n",
    "            \n",
    "    return np.array(images), np.array(labels), label_map, filenames  # Devolver las imágenes, etiquetas, mapa de etiquetas y nombres de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para detección y reconocimiento de objetos\n",
    "def detect_and_recognize(image_path, model, label_map, filenames, data_dir):\n",
    "    img = cv2.imread(image_path)  # Cargar la imagen\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Redimensionar la imagen\n",
    "    img = img / 255.0  # Normalizar la imagen\n",
    "    img = np.expand_dims(img, axis=0)  # Añadir dimensión para batch\n",
    "\n",
    "    predictions = model.predict(img)  # Hacer predicción\n",
    "    predicted_class = np.argmax(predictions)  # Obtener clase predicha\n",
    "    \n",
    "    # Verificar si la imagen entregada coincide con alguna del dataset\n",
    "    class_name = [label for label, idx in label_map.items() if idx == predicted_class][0]\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for img_file, img_path in filenames:\n",
    "        if img_file.startswith(class_name):  # Verificar si la imagen pertenece a la clase predicha\n",
    "            dataset_img = cv2.imread(img_path)\n",
    "            dataset_img = cv2.resize(dataset_img, (IMG_SIZE, IMG_SIZE))\n",
    "            dataset_img = dataset_img / 255.0\n",
    "\n",
    "            if np.allclose(img, np.expand_dims(dataset_img, axis=0), atol=1e-2):\n",
    "                return f\"La imagen fue encontrada y el nombre es '{img_file}'\", img_path\n",
    "\n",
    "    return \"La imagen no existe en el dataset\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw/John_Paul_II\n",
      "lfw/Lucio_Gutierrez\n",
      "lfw/Alvaro_Uribe\n",
      "lfw/WilfridoAlmache\n",
      "lfw/Oscar_De_La_Hoya\n",
      "lfw/Prince_Felipe\n",
      "lfw/Hugo_Chavez\n",
      "lfw/Infanta_Cristina\n"
     ]
    }
   ],
   "source": [
    "# Ruta del directorio de datos (ajusta esta ruta según tu sistema)\n",
    "data_dir = 'lfw'  # Ajusta según sea necesario\n",
    "\n",
    "# Cargar y preprocesar las imágenes\n",
    "images, labels, label_map, filenames = load_and_preprocess_images(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cargar el modelo pre-entrenado MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "#baseModel = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "# Añadir capas personalizadas\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(label_map), activation='softmax')(x)\n",
    "\n",
    "# Definir el modelo completo\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congelar las capas del modelo base para no entrenarlas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 09:47:09.691272: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 77672448 exceeds 10% of free system memory.\n",
      "2024-06-16 09:47:13.406852: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2024-06-16 09:47:13.456851: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2024-06-16 09:47:13.501235: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154140672 exceeds 10% of free system memory.\n",
      "2024-06-16 09:47:13.562468: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 156905472 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 779ms/step - accuracy: 0.3717 - loss: 2.0622 - val_accuracy: 0.4545 - val_loss: 1.5534\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 519ms/step - accuracy: 0.7075 - loss: 0.9868 - val_accuracy: 0.6970 - val_loss: 1.0729\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 527ms/step - accuracy: 0.7420 - loss: 0.7336 - val_accuracy: 0.6364 - val_loss: 0.9504\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 527ms/step - accuracy: 0.9066 - loss: 0.3215 - val_accuracy: 0.4545 - val_loss: 1.3999\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.9229 - loss: 0.2476 - val_accuracy: 0.6667 - val_loss: 0.8285\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 499ms/step - accuracy: 0.9754 - loss: 0.1123 - val_accuracy: 0.6364 - val_loss: 0.7597\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 510ms/step - accuracy: 0.9918 - loss: 0.0870 - val_accuracy: 0.7273 - val_loss: 0.7512\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 508ms/step - accuracy: 0.9961 - loss: 0.0466 - val_accuracy: 0.7273 - val_loss: 0.9114\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.6667 - val_loss: 0.8525\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.6667 - val_loss: 0.7852\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6632 - loss: 0.7933 \n",
      "Precisión en el conjunto de prueba: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el rendimiento del modelo en el conjunto de datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en el conjunto de prueba: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "La imagen no existe en el dataset\n",
      "La imagen no fue encontrada en el dataset.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función de detección y reconocimiento\n",
    "image_path = 'siCarpeta.jpg'  # Ajusta según sea necesario\n",
    "detected_label, detected_img_path = detect_and_recognize(image_path, model, label_map, filenames, data_dir)\n",
    "print(detected_label)\n",
    "\n",
    "# Mostrar la imagen si fue encontrada\n",
    "if detected_img_path:\n",
    "    img = cv2.imread(detected_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Imagen encontrada: {detected_label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"La imagen no fue encontrada en el dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
