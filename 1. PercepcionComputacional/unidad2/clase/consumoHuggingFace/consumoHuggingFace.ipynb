{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Instalación de la biblioteca transformers y torch\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-19 20:41:59.709207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 20:42:00.929546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Importamos `pipeline` de la librería `transformers`\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation',model='gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Había una vez Pachon de de la la mia (Tessino), \"La manión por no mía que los dias el de llenório para las jugar por son címo\".\n"
     ]
    }
   ],
   "source": [
    "# Cargamos un pipeline de generación de texto\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generamos texto con el modelo cargado\n",
    "text = generator(\"Había una vez\", max_length=50, num_return_sequences=1)\n",
    "print(text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: In the future, AI will\n",
      "Generated Text: In the future, AI will evolve with other AI technologies like the artificial intelligence (AI) or machine learning technologies (MLR). These will work together to build a better, more efficient, more ethical society.\n",
      "\n",
      "In my book, we look\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The secret to happiness is\n",
      "Generated Text: The secret to happiness is that no one ever asks, for fear of being met. People come up with ideas because someone wants to hear them.\n",
      "\n",
      "\"I am not a big fan of religion. It is something outwards, and I believe\n",
      "\n",
      "Prompt: The quick brown fox\n",
      "Generated Text: The quick brown foxes were on his side, and were almost ready when Ruby stepped in and tried to fight him as soon as she saw him. The other fox ran over quickly and jumped in his flight, only to find it was too late.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de generación de texto con diferentes prompts\n",
    "prompts = [\n",
    "    \"In the future, AI will\",\n",
    "    \"The secret to happiness is\",\n",
    "    \"The quick brown fox\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    text = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Generated Text: {text[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Qué hacen los estudiantes en la Universidad de los Hemisferios?\n",
      "Respuesta: Ecuador\n"
     ]
    }
   ],
   "source": [
    "# Cargamos un pipeline de respuesta a preguntas\n",
    "qa_pipeline = pipeline('question-answering')\n",
    "\n",
    "# Definimos el contexto y la pregunta\n",
    "context = \"La Universidad de los Hemisferios es una universidad reconocida por su calidad académica dentro de Ecuador.\"\n",
    "question = \"¿Qué hacen los estudiantes en la Universidad de los Hemisferios?\"\n",
    "\n",
    "# Obtenemos la respuesta\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(f\"Pregunta: {question}\")\n",
    "print(f\"Respuesta: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos un pipeline de resumen\n",
    "summarizer = pipeline('summarization')\n",
    "\n",
    "# Texto largo para resumir\n",
    "long_text = \"\"\"\n",
    "La inteligencia artificial (IA) se refiere a la simulación de la inteligencia humana en máquinas que están programadas para pensar como humanos y \n",
    "imitar sus acciones. El término también se puede aplicar a cualquier máquina que exhiba rasgos asociados con una mente humana como el aprendizaje y \n",
    "la resolución de problemas. La característica ideal de la inteligencia artificial es su capacidad para racionalizar y tomar acciones que tengan \n",
    "la mejor posibilidad de alcanzar un objetivo específico. Un subconjunto de la inteligencia artificial es el aprendizaje automático, que se refiere a \n",
    "la idea de que los sistemas informáticos pueden aprender de datos, identificar patrones y tomar decisiones con una mínima intervención humana.\n",
    "\"\"\"\n",
    "\n",
    "# Generamos el resumen\n",
    "summary = summarizer(long_text, max_length=50, min_length=25, do_sample=False)\n",
    "print(\"Resumen:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Persistent homology is a method for computing topological features of a space at different spatial resolutions. More persistent features are detected over a wide range of spatial scales and are deemed more likely to represent true features of the underlying space rather than artifacts of sampling, noise, or particular choice of parameters\n",
      "Traducción: La homología persistente es un método para calcular las características topológicas de un espacio en diferentes resoluciones espaciales. Se detectan características más persistentes en una amplia gama de escalas espaciales y se considera más probable que representen características verdaderas del espacio subyacente en lugar de artefactos de muestreo, ruido o elección particular de parámetros.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos un pipeline de traducción especificando el modelo\n",
    "!pip install sentencepiece\n",
    "import sentencepiece \n",
    "translation_pipeline = pipeline('translation', model='Helsinki-NLP/opus-mt-en-es')\n",
    "\n",
    "# Definimos el texto a traducir\n",
    "text = \"Persistent homology is a method for computing topological features of a space at different spatial resolutions. More persistent features are detected over a wide range of spatial scales and are deemed more likely to represent true features of the underlying space rather than artifacts of sampling, noise, or particular choice of parameters\"\n",
    "\n",
    "# Obtenemos la traducción.\n",
    "result = translation_pipeline(text)\n",
    "print(f\"Texto original: {text}\")\n",
    "print(f\"Traducción: {result[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Result:\n",
      "Label: NEGATIVE, Score: 0.9995490908622742\n"
     ]
    }
   ],
   "source": [
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Text to analyze sentiment\n",
    "text = \"I'm very sad today because I just lost my work! \"\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment_result = sentiment_analyzer(text)\n",
    "\n",
    "# Print the sentiment result\n",
    "print(\"Sentiment Analysis Result:\")\n",
    "for result in sentiment_result:\n",
    "    print(f\"Label: {result['label']}, Score: {result['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:\n",
      "    Name Age             Interest\n",
      "0   Gaby  23  Persistent Homology\n",
      "1    May  26   Numerical Analysis\n",
      "2  Andre  23   Functinal Analysis\n",
      "Question: What is Gaby interest?\n",
      "Answer: Persistent Homology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/transformers/models/tapas/tokenization_tapas.py:2674: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/transformers/models/tapas/tokenization_tapas.py:1473: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load a table-question-answering pipeline\n",
    "table_qa = pipeline(\"table-question-answering\", model=\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "# Create a table as a pandas DataFrame\n",
    "data = {\n",
    "    \"Name\": [\"Gaby\", \"May\", \"Andre\"],\n",
    "    \"Age\": [\"23\", \"26\", \"23\"],  # Ensure all entries are strings\n",
    "    \"Interest\": [\"Persistent Homology\", \"Numerical Analysis\", \"Functinal Analysis\"]\n",
    "}\n",
    "table = pd.DataFrame(data)\n",
    "\n",
    "# Ensure the table is in the correct format\n",
    "print(\"Table:\")\n",
    "print(table)\n",
    "\n",
    "# Question about the table\n",
    "question = \"What is Gaby interest?\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = table_qa(table=table, query=question)\n",
    "\n",
    "# Print the question and the answer\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'two birds are standing next to each other birds'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
    "captioner(\"parrots.png\")\n",
    "## [{'generated_text': 'two birds are standing next to each other '}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to ydshieh/vit-gpt2-coco-en and revision 65636df (https://huggingface.co/ydshieh/vit-gpt2-coco-en).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'two birds are standing next to each other '}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "captioner = pipeline(\"image-to-text\")\n",
    "captioner(\"parrots.png\")\n",
    "## [{'generated_text': 'two birds are standing next to each other '}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (4.41.2)\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Collecting importlib-metadata (from diffusers)\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: Pillow in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->diffusers)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/walmache/MEGA/autoCapacitacion/Maestria-IA/1.percepcionComputacional/repos/practicasPercepcionComputacional/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading diffusers-0.29.0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: zipp, importlib-metadata, diffusers\n",
      "Successfully installed diffusers-0.29.0 importlib-metadata-7.1.0 zipp-3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Descargar el modelo y el tokenizador\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Crear el pipeline de Stable Diffusion\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# Descripción de texto para generar la imagen\n",
    "prompt = \"A fantasy landscape with mountains, a river, and a castle\"\n",
    "\n",
    "# Generar la imagen\n",
    "with torch.autocast(\"cuda\"):\n",
    "    image = pipe(prompt)[\"sample\"][0]\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
